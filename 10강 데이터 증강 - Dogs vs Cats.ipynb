{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df79e13",
   "metadata": {
    "id": "8df79e13"
   },
   "source": [
    "# Dogs vs Cats 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c960a9",
   "metadata": {
    "id": "85c960a9"
   },
   "source": [
    "[Dogs vs Cats](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition) 데이터셋에는 훈련용으로 고양이, 개 사진이 각각 12,500장 그리고 테스트용으로 총 12,500장이 있습니다.  \n",
    "이번 실습의 목표는 적은 수의 데이터만 주어져 있을 때 데이터 증강(data augmentation)을 통해 신경망의 성능을 끌어올리는 것 입니다.  \n",
    "따라서, 전체 데이터 셋을 사용하지 않고 아주 일부분만을 사용하겠습니다.  \n",
    "![](https://drive.google.com/thumbnail?id=1IwvrXV6LNsedoxM5iOrfK5vlnUGw0qyG&sz=s4000)\n",
    "\n",
    "실습에 사용할 일부분을 미리 추려내서 압축한 후 구글 드라이브에 업로드했습니다.  \n",
    "`gdown` 라이브러리를 사용하면 구글 드라이브에 링크된 파일을 다운로드 받을 수 있습니다. (프롬프트에서 `pip install gdown`으로 설치)  \n",
    "`os.path.isdir('cats_vs_dogs_small')`은 현재 작업디렉토리에 cats_vs_dogs_small란 이름의 디렉토리가 있으면 True를 리턴합니다.  \n",
    "`zipfile` 라이브러리의 `extractall()`을 써서 압축파일의 하위 디렉토리까지 모두 풀어줍니다.  \n",
    "파일탐색기로 현재 작업디렉토리 밑에 cats_vs_dogs_small 디렉토리, 그 밑에 test, train, validation 디렉토리, 그밑에 각각 cat, dog 디렉토리가 생성된 걸 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e9f2c2",
   "metadata": {
    "id": "b7e9f2c2"
   },
   "outputs": [],
   "source": [
    "import gdown, zipfile, os\n",
    "\n",
    "if not os.path.isdir('cats_vs_dogs_small'):\n",
    "    gdown.download(id='1z2WPTBUI-_Q2jZtcRtQL0Vxigh-z6dyW', output='cats_vs_dogs_small.zip')\n",
    "    cats_vs_dogs_small = zipfile.ZipFile('cats_vs_dogs_small.zip')\n",
    "    cats_vs_dogs_small.extractall()\n",
    "    cats_vs_dogs_small.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e9b67",
   "metadata": {
    "id": "f97e9b67"
   },
   "source": [
    "훈련용 고양이 디렉토리 안에는 다음과 같은 이름의 파일들이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2847dd",
   "metadata": {
    "id": "2f2847dd"
   },
   "outputs": [],
   "source": [
    "print(sorted(os.listdir(\"./cats_vs_dogs_small/train/cat\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1868c1",
   "metadata": {
    "id": "9f1868c1"
   },
   "source": [
    "개와 고양이 사진이 각각 훈련용 1,000장, 검증용 500장, 테스트용 1,000장이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68081ab",
   "metadata": {
    "id": "f68081ab"
   },
   "outputs": [],
   "source": [
    "print(\"train : \"+sorted(os.listdir(\"./cats_vs_dogs_small/train/cat\"))[0]+\" ~ \"+sorted(os.listdir(\"./cats_vs_dogs_small/train/cat\"))[-1])\n",
    "print(\"validation : \"+sorted(os.listdir(\"./cats_vs_dogs_small/validation/cat\"))[0]+\" ~ \"+sorted(os.listdir(\"./cats_vs_dogs_small/validation/cat\"))[-1])\n",
    "print(\"test : \"+sorted(os.listdir(\"./cats_vs_dogs_small/test/cat\"))[0]+\" ~ \"+sorted(os.listdir(\"./cats_vs_dogs_small/test/cat\"))[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a3e87e",
   "metadata": {
    "id": "85a3e87e"
   },
   "source": [
    "고양이 첫 훈련 이미지 25장입니다.  \n",
    "해상도가 제각각이고 사람과 찍은 사진, 여러마리 사진, 철창에 가려진 사진도 보이네요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd0119",
   "metadata": {
    "id": "5fcd0119"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    img_path = f'./cats_vs_dogs_small/train/cat/cat.{i}.jpg'\n",
    "    img = image.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e92a8a9",
   "metadata": {
    "id": "6e92a8a9"
   },
   "source": [
    "**[실습1] (2분) 강아지 첫 훈련 이미지 25장을 5$\\times$5 모아찍기로 출력하시오.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5a6982",
   "metadata": {
    "id": "0a5a6982"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44e584ef",
   "metadata": {
    "id": "44e584ef"
   },
   "source": [
    "# 입력 파이프라인 API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f380a",
   "metadata": {
    "id": "748f380a"
   },
   "source": [
    "리스트와 튜플은 순회 가능한 객체(iterable object)입니다.  \n",
    "사실 반복문에서 `in` 다음에 오는 것은 모두 순회 가능한 객체입니다.  \n",
    "순회 가능한 객체는 `iter`를 씌운 후 `next`를 적용하면 순서대로 내장된 값을 리턴합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cbf97f",
   "metadata": {
    "id": "69cbf97f"
   },
   "outputs": [],
   "source": [
    "x = [\"a\",\"b\",\"c\"]\n",
    "iterator = iter(x)\n",
    "print(next(iterator))\n",
    "print(next(iterator))\n",
    "print(next(iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c700b6ae",
   "metadata": {
    "id": "c700b6ae"
   },
   "source": [
    "**[실습2] (2분) `range(3)`에 `iter`를 씌운 후 `next`를 차례로 적용하시오.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad3f069",
   "metadata": {
    "id": "4ad3f069"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d040afba",
   "metadata": {
    "id": "d040afba"
   },
   "source": [
    "텐서플로우는 대용량 데이터를 다룰때 통상적으로 [tf.data](https://www.tensorflow.org/api_docs/python/tf/data) API를 이용해 입력데이터를 `Dataset`으로 변환해 처리합니다.  \n",
    "`Dataset`은 순회가능한 객체(iterable object)입니다.  \n",
    "[from_tensor_slices](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices) 메서드를 이용하면 입력 텐서를 슬라이싱해서 `Dataset`을 만듭니다.  \n",
    "![](https://drive.google.com/thumbnail?id=1c_shLACT0K4xWVN7MMZ3SOIPo9OTQBzV&sz=s4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f323f",
   "metadata": {
    "id": "e78f323f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "dataset = np.arange(100).reshape(20,5)\n",
    "print(dataset)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448d4c5a",
   "metadata": {
    "id": "448d4c5a"
   },
   "source": [
    "[batch](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch) 메서드를 써서 배치 단위로 묶을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a732c",
   "metadata": {
    "id": "a98a732c"
   },
   "outputs": [],
   "source": [
    "batched_dataset = dataset.batch(4)\n",
    "\n",
    "for batch in batched_dataset:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc05bfd",
   "metadata": {
    "id": "9fc05bfd"
   },
   "source": [
    "[tf.keras.utils.image_dataset_from_directory](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory)을 사용하면 디렉토리로부터 데이터를 읽어들여 `Dataset`을 만듭니다.  \n",
    "- `image_size=(180, 180)` : 해상도가 제 각각 이었는데 180$\\times$180으로 통일해줍니다. 그래야 신경망을 구성할 수 있겠지요.  \n",
    "- `batch_size=32` : 입력 데이터셋을 32개의 배치단위로 묶습니다.\n",
    "- `shuffle=True` : True가 디폴트 설정인데 입력데이터를 랜덤하게 섞습니다.\n",
    "- `labels='inferred'`: inferred가 디폴트 설정인데 디렉토리 이름의 알파벳 순서에 따라 텐서플로우가 라벨을 0부터 차례대로 붙여줍니다. train, validation, test 디렉토리 밑에 모두 cat, dog 디렉토리가 있기 때문에 고양이 사진은 0, 강아지 사진은 1로 라벨을 붙여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26556dc",
   "metadata": {
    "id": "c26556dc"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    base_dir / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    base_dir / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    base_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff400f42",
   "metadata": {
    "id": "ff400f42"
   },
   "source": [
    "iter로 묶은후 next를 적용하면 첫번째 배치묶음을 출력할 수 있습니다.  \n",
    "텐서와 라벨의 튜플입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91d2ac",
   "metadata": {
    "id": "2d91d2ac"
   },
   "outputs": [],
   "source": [
    "iterator = iter(train_dataset)\n",
    "batch_1 = next(iterator)\n",
    "print(batch_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a439359b",
   "metadata": {
    "id": "a439359b"
   },
   "source": [
    "두번째 배치묶음입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ccdf1",
   "metadata": {
    "id": "cc5ccdf1"
   },
   "outputs": [],
   "source": [
    "batch_2 = next(iterator)\n",
    "print(batch_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e832083",
   "metadata": {
    "id": "5e832083"
   },
   "source": [
    "모든 라벨을 출력해봤습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405896d",
   "metadata": {
    "id": "d405896d"
   },
   "outputs": [],
   "source": [
    "for data in train_dataset:\n",
    "    print(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eeb185",
   "metadata": {
    "id": "66eeb185"
   },
   "source": [
    "**[실습3] (10분) 첫번재 배치묶음을 8$\\times$4 모아찍기로 출력하시오. 이미지 밑에 라벨을 출력하시오..**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65307a0",
   "metadata": {
    "id": "a65307a0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3f3e0db",
   "metadata": {
    "id": "d3f3e0db"
   },
   "source": [
    "# 적은 데이터로 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1322f",
   "metadata": {
    "id": "c1b1322f"
   },
   "source": [
    "합성곱 신경망을 구성하겠습니다.  \n",
    "데이터가 복잡한 만큼 전보다 더 Deep합니다.  \n",
    "tf.keras.layers.MaxPooling2D는 tf.keras.layers.MaxPool2D와 완전히 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ad0d0",
   "metadata": {
    "id": "cf1ad0d0"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Rescaling, Flatten, Dense\n",
    "\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = Rescaling(1./255)(inputs)\n",
    "x = Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be66e4ca",
   "metadata": {
    "id": "be66e4ca"
   },
   "source": [
    "콜백으로 자동저장을 지정합니다.  \n",
    "위에서 만든`Dataset`으로 학습과 검증을 합니다.  \n",
    "배치크기는 지정할 필요 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecfced4",
   "metadata": {
    "id": "8ecfced4"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"convnet_from_scratch.keras\",\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_loss\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa2df41",
   "metadata": {
    "id": "2aa2df41"
   },
   "source": [
    "데이터가 적어서 과적합이 심하게 일어납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48534966",
   "metadata": {
    "id": "48534966"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8dc59d",
   "metadata": {
    "id": "1a8dc59d"
   },
   "source": [
    "최고 성능일때 자동저장된 모델을 불러왔습니다.  \n",
    "찍어도 50%라는 점을 생각하면 기대보다 낮은 정확도입니다.  \n",
    "데이터의 복잡도에 비해 훈련 데이터 수가 너무 적어서인 듯 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc2710e",
   "metadata": {
    "id": "7fc2710e"
   },
   "outputs": [],
   "source": [
    "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"테스트 정확도: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67046198",
   "metadata": {
    "id": "67046198"
   },
   "source": [
    "# 데이터 증강"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1554fedd",
   "metadata": {
    "id": "1554fedd"
   },
   "source": [
    "모델을 구성하고 하이퍼 파라미터를 튜닝하는 일보다 현실에서는 충분한 데이터를 확보하는게 더 어려울 수 있습니다.  \n",
    "적은 데이터로부터 변형을 통해 데이터 양을 인위적으로 늘리는 기법을 데이터 증강 (data augmentation)이라고 합니다.  \n",
    "![](https://drive.google.com/thumbnail?id=1kjG_oa9qvarB8UTX63LkSia9_a-jxDPZ&sz=s4000)\n",
    "\n",
    "---\n",
    "이미지 데이터는 대칭, 회전, 확대, 축소등을 통해 데이터를 인위적으로 늘릴 수 있습니다.  \n",
    "대칭은 [tf.keras.layers.RandomFlip](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomFlip)으로, 회전은 [tf.keras.layers.RandomRotation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation)으로, 확대 축소는 [tf.keras.layers.RandomZoom](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomZoom)으로 구현되어 있습니다.  \n",
    "Squential 클래스로 묶겠습니다.\n",
    "- `RandomFlip(\"horizontal\")` : 랜덤하게 좌우대칭\n",
    "- `RandomRotation(0.1)` : 랜덤하게 -0.1×360° ~ 0.1×360°만큼 회전\n",
    "- `RandomZoom(0.2)` : 상하로 랜덤하게 -20% ~ 20% 확대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f3b7a",
   "metadata": {
    "id": "5f2f3b7a"
   },
   "outputs": [],
   "source": [
    "from keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [RandomFlip(\"horizontal\"),\n",
    "     RandomRotation(0.1),\n",
    "     RandomZoom(0.2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc68dfa",
   "metadata": {
    "id": "fbc68dfa"
   },
   "source": [
    "첫번째 배치묶음의 첫번째 데이터에 대해서 증강을 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f3579",
   "metadata": {
    "id": "497f3579"
   },
   "outputs": [],
   "source": [
    "img = batch_1[0][0]\n",
    "\n",
    "plt.imshow(img/255)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    augmented_img = data_augmentation(img[np.newaxis,:,:,:])\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(augmented_img[0]/255)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8def53",
   "metadata": {
    "id": "fb8def53"
   },
   "source": [
    "**[실습4] (10분) (i) MNIST 첫번째 훈련 데이터에 대하여 랜덤하게 -0.1$\\times$360° ~ 0.1$\\times$360°만큼 회전한 이미지 25장을 5$\\times$5 모아찍기로 출력하시오.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba42b9e",
   "metadata": {
    "id": "4ba42b9e"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b72545",
   "metadata": {
    "id": "f6b72545"
   },
   "source": [
    "**(ii) MNIST 첫번째 훈련 데이터에 대하여 상하좌우로 랜덤하게 20프로 이내로 평행이동한 이미지 25장을 5$\\times$5 모아찍기로 출력하시오.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd18d18",
   "metadata": {
    "id": "fcd18d18"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df17968d",
   "metadata": {
    "id": "df17968d"
   },
   "source": [
    "# 데이터 증강을 통한 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00971f4",
   "metadata": {
    "id": "e00971f4"
   },
   "source": [
    "첫번째 층에서 입력 데이터를 변형합니다.  \n",
    "에퍽 수만큼 동일한 데이터가 반복해서 들어올텐데 들어올때마다 변형해서 적은 훈련 데이터 개수를 보완해줍니다.  \n",
    "과적합을 피하기 위해 Dropout층을 추가했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac421e1f",
   "metadata": {
    "id": "ac421e1f"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = Rescaling(1./255)(x)\n",
    "x = Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f05daf",
   "metadata": {
    "id": "b3f05daf"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_loss\")]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95070b4c",
   "metadata": {
    "id": "95070b4c"
   },
   "source": [
    "데이터 증강을 통해 대략 70% → 80%의 성능 향상을 이뤄냈습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a5852",
   "metadata": {
    "id": "892a5852"
   },
   "outputs": [],
   "source": [
    "test_model = keras.models.load_model(\n",
    "    \"convnet_from_scratch_with_augmentation.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"테스트 정확도: {test_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
